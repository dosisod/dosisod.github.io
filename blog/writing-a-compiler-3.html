<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <meta name="description" content="" />
  <link rel="stylesheet" href="/styles/main.css">
  <link rel="stylesheet" href="/styles/gruvbox-dark-hard.css" />
  <title>Writing a Compiler (Part 3): Classifying + Better Tokenizing</title>
</head>
<body>

<main>
<h1>Writing a Compiler (Part 3): Classifying + Better Tokenizing</h1>
<br>
<p>After we have some tokens that have been strung together, the next step is to
classify them, and give them more meaning. Classification in and of itself is
not super interesting or super hard, so in addition to classifying the tokens,
we will add basic parsing of comments, which will require us to make some changes
to our tokenizer.</p>
<br>
<p>Let's begin!</p>
<br>
<blockquote>The code used for this blog can be viewed <a href="https://github.com/dosisod/write-a-compiler/tree/part3">here</a>.</blockquote>
<br>
<h2>Basic Token Type Classification</h2>
<br>
<p>Let's start by adding some more token types to our <code class="hljs">TokenType</code> enum:</p>
<br>
<pre class="hljs"> class TokenType(Enum):
     IDENTIFIER = auto()
     WHITESPACE = auto()
     NEWLINE = auto()
<span class="hljs-addition">+    PLUS = auto()</span>
<span class="hljs-addition">+    DASH = auto()</span>
<span class="hljs-addition">+    ASTERISK = auto()</span>
<span class="hljs-addition">+    SLASH = auto()</span>
<span class="hljs-addition">+    POWER = auto()</span>
<span class="hljs-addition">+    OPEN_PAREN = auto()</span>
<span class="hljs-addition">+    CLOSE_PAREN = auto()</span>
<span class="hljs-addition">+    EQUAL = auto()</span>
<span class="hljs-addition">+    LESS_THEN = auto()</span>
<span class="hljs-addition">+    GREATER_THEN = auto()</span>
<span class="hljs-addition">+    DOT = auto()</span>
<span class="hljs-addition">+    COMMENT = auto()</span></pre>

<br>
<p>All of these new token types (except <code class="hljs">COMMENT</code>) are single-character tokens,
meaning we won't need to add a lot of code to properly classify these tokens.
Also, note that we are using <code class="hljs">PLUS</code> instead of <code class="hljs">ADD</code>, and <code class="hljs">DASH</code> instead of
<code class="hljs">MINUS</code>. Although it might be tempting to name these tokens after their uses,
things can start to get confusing when you lock a token to a specific use case.
For example: A "dash" can be used for both binary subtraction, and unary negation.
An example of that would be <code class="hljs">1 - 2</code> (binary) and <code class="hljs">- 1</code> (unary). By using the
ambiguous term "dash", we can refer to both operations, since we use the token
type to refer to the token, not the way the token is used.</p>
<br>
<p>Next we need to update our <code class="hljs">char_to_token_type</code> function to handle the new
token types we just added:</p>
<br>
<pre class="hljs"> def char_to_token_type(c: str) -&gt; Optional[TokenType]:
<span class="hljs-deletion">-    if c == &quot;\n&quot;:</span>
<span class="hljs-deletion">-        return TokenType.NEWLINE</span>
<span class="hljs-addition">+    simple_token_types = {</span>
<span class="hljs-addition">+        &quot;\n&quot;: TokenType.NEWLINE,</span>
<span class="hljs-addition">+        &quot;+&quot;: TokenType.PLUS,</span>
<span class="hljs-addition">+        &quot;-&quot;: TokenType.DASH,</span>
<span class="hljs-addition">+        &quot;*&quot;: TokenType.ASTERISK,</span>
<span class="hljs-addition">+        &quot;/&quot;: TokenType.SLASH,</span>
<span class="hljs-addition">+        &quot;^&quot;: TokenType.POWER,</span>
<span class="hljs-addition">+        &quot;(&quot;: TokenType.OPEN_PAREN,</span>
<span class="hljs-addition">+        &quot;)&quot;: TokenType.CLOSE_PAREN,</span>
<span class="hljs-addition">+        &quot;=&quot;: TokenType.EQUAL,</span>
<span class="hljs-addition">+        &quot;&lt;&quot;: TokenType.LESS_THEN,</span>
<span class="hljs-addition">+        &quot;&gt;&quot;: TokenType.GREATER_THEN,</span>
<span class="hljs-addition">+        &quot;.&quot;: TokenType.DOT,</span>
<span class="hljs-addition">+        &quot;#&quot;: TokenType.COMMENT,</span>
<span class="hljs-addition">+    }</span>
<span class="hljs-addition">+</span>
<span class="hljs-addition">+    if token_type := simple_token_types.get(c):</span>
<span class="hljs-addition">+        return token_type</span></pre>

<br>
<p>This will basically just match up a character like <code class="hljs">+</code> to it's respective token
type. We use the <a href="https://peps.python.org/pep-0572/">walrus operator</a> which allows
us to assign and use our temporary <code class="hljs">token_type</code> variable in one line. We use the
<code class="hljs">.get(c)</code> method instead of using <code class="hljs">[c]</code> because <code class="hljs">.get</code> will return <code class="hljs">None</code> if the
key is not found, whereas using a subscript (<code class="hljs">[]</code>) will cause a <code class="hljs">KeyError</code> exception.
Not very pleasant!</p>
<br>
<p>When we run <code class="hljs">pytest</code>, we will see that our <code class="hljs">test_tokenize_unknown_token</code>
test fails, since <code class="hljs">+</code> is now a recognized token type. To fix it, we change
it to something which doesn't have a token type yet:</p>
<br>
<pre class="hljs"> def test_tokenize_unknown_token():
<span class="hljs-deletion">-    tokens = tokenize(&quot;+&quot;)</span>
<span class="hljs-addition">+    tokens = tokenize(&quot;!&quot;)</span>

<span class="hljs-deletion">-    assert tokens == [Token(&quot;+&quot;, 1, 1, None)]</span>
<span class="hljs-addition">+    assert tokens == [Token(&quot;!&quot;, 1, 1, None)]</span></pre>

<br>
<h2>Cleanup</h2>
<br>
<p>As we start to make our tokenizer more complex, it is important to recognize things
which won't work well in the future. Currently, the <code class="hljs">LocationInfo</code> and <code class="hljs">Token</code> concepts
are very similar, and so we might as well just use <code class="hljs">Token</code>'s for everything.
That way we will just be grouping/merging/manipulating tokens, instead of both token and
location info objects.</p>
<br>
<p>Let's start by re-writing our <code class="hljs">tokenize</code> function:</p>
<br>
<pre class="hljs"><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize</span>(<span class="hljs-params">code: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-type">List</span>[Token]:
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">collapse_token</span>(<span class="hljs-params">tokens</span>):
        contents = <span class="hljs-string">&quot;&quot;</span>.join([token.content <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> tokens])

        first = tokens[<span class="hljs-number">0</span>]
        <span class="hljs-keyword">return</span> Token(contents, first.line, first.column, first.<span class="hljs-built_in">type</span>)

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">location_info_to_token</span>(<span class="hljs-params">info: LocationInfo</span>) -&gt; Token:
        <span class="hljs-keyword">return</span> Token(
            info.char, info.line, info.column, char_to_token_type(info.char)
        )

    tokens = [
        location_info_to_token(info) <span class="hljs-keyword">for</span> info <span class="hljs-keyword">in</span> generate_location_info(code)
    ]

    grouped = groupby(tokens, <span class="hljs-keyword">lambda</span> token: token.<span class="hljs-built_in">type</span>)

    <span class="hljs-keyword">return</span> [collapse_token(<span class="hljs-built_in">list</span>(group[<span class="hljs-number">1</span>])) <span class="hljs-keyword">for</span> group <span class="hljs-keyword">in</span> grouped]</pre>

<br>
<p>Basically, once we get our location info, we immediately turn it into a token,
and then group on the token's type. This will make things easier down below.</p>
<br>
<h2>Comment Parsing</h2>
<br>
<p>Now we need are going to add the ability to parse comments. These are the basic
requirements for a comment token:</p>
<br>
<ul>
<li>Starts with a <code class="hljs">#</code> character</li>
<li>Ends when EOL (end of line, newline) is reached</li>
<li>Ends when EOF (end of file) is reached</li>
</ul>
<br>
<p>To achieve this, we will write a function that will take the many tokens inside
of our comment and group them into a single "comment" token. Let's write some tests
to see what we should expect:</p>
<br>
<pre class="hljs"><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_collapse_comment</span>():
    tokens = tokenize(<span class="hljs-string">&quot;# hello world&quot;</span>)

    <span class="hljs-keyword">assert</span> tokens == [Token(<span class="hljs-string">&quot;# hello world&quot;</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, TokenType.COMMENT)]


<span class="hljs-keyword">def</span> <span class="hljs-title function_">test_collapse_comment_respect_newlines</span>():
    tokens = tokenize(<span class="hljs-string">&quot;# hello\n# world&quot;</span>)

    <span class="hljs-keyword">assert</span> tokens == [
        Token(<span class="hljs-string">&quot;# hello&quot;</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, TokenType.COMMENT),
        Token(<span class="hljs-string">&quot;\n&quot;</span>, <span class="hljs-number">1</span>, <span class="hljs-number">8</span>, TokenType.NEWLINE),
        Token(<span class="hljs-string">&quot;# world&quot;</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, TokenType.COMMENT),
    ]</pre>

<br>
<p>If we run our tests, we will see that the new tests that we added are not passing.
Let's write some code to fix that!</p>
<br>
<pre class="hljs"><span class="hljs-keyword">def</span> <span class="hljs-title function_">collapse_comment</span>(<span class="hljs-params">tokens: <span class="hljs-type">List</span>[Token]</span>) -&gt; <span class="hljs-type">List</span>[Token]:
    out: <span class="hljs-type">List</span>[Token] = []
    in_comment = <span class="hljs-literal">False</span>

    <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> tokens:
        <span class="hljs-keyword">if</span> token.<span class="hljs-built_in">type</span> == TokenType.COMMENT:
            in_comment = <span class="hljs-literal">True</span>

        <span class="hljs-keyword">elif</span> in_comment:
            <span class="hljs-keyword">if</span> token.<span class="hljs-built_in">type</span> == TokenType.NEWLINE:
                in_comment = <span class="hljs-literal">False</span>

            <span class="hljs-keyword">else</span>:
                out[-<span class="hljs-number">1</span>].content += token.content
                <span class="hljs-keyword">continue</span>

        out.append(token)

    <span class="hljs-keyword">return</span> out</pre>

<br>
<p>This (in short) loop through each token until we find a token with a <code class="hljs">COMMENT</code> type.
Once we find it, we will append the contents of each token to the last token in our
<code class="hljs">out</code> list (the comment token), until we reach a <code class="hljs">NEWLINE</code>, or the loop ends.</p>
<br>
<p>And now we need to update our <code class="hljs">tokenize</code> function:</p>
<br>
<pre class="hljs">     ]

<span class="hljs-addition">+    tokens = collapse_comment(tokens)</span>
<span class="hljs-addition">+</span>
     grouped = groupby(tokens, lambda token: token.type)</pre>

<br>
<p>When we run our tests again, they should be passing.</p>
<br>
<h2>More Cleanup/Refactoring</h2>
<br>
<p>As we mentioned before, the <code class="hljs">LocationInfo</code>'s look very similar to the <code class="hljs">Token</code>'s.
It would probably be best to just merge the two:</p>
<br>
<pre class="hljs"><span class="hljs-deletion">-class LocationInfo(NamedTuple):</span>
<span class="hljs-deletion">-    char: str</span>
<span class="hljs-deletion">-    line: int</span>
<span class="hljs-deletion">-    column: int</span>
<span class="hljs-deletion">-</span>
<span class="hljs-deletion">-</span>
<span class="hljs-deletion">-def generate_location_info(</span>
<span class="hljs-addition">+def generate_token_locations(</span>
     code: str,
<span class="hljs-deletion">-) -&gt; Generator[LocationInfo, None, None]:</span>
<span class="hljs-addition">+) -&gt; Generator[Token, None, None]:</span>
     line = 1
     column = 1

     for c in code:
<span class="hljs-deletion">-        yield LocationInfo(c, line, column)</span>
<span class="hljs-addition">+        yield Token(c, line, column)</span>

 ...

<span class="hljs-deletion">-    def location_info_to_token(info: LocationInfo) -&gt; Token:</span>
<span class="hljs-deletion">-        return Token(</span>
<span class="hljs-deletion">-            info.char, info.line, info.column, char_to_token_type(info.char)</span>
<span class="hljs-deletion">-        )</span>
<span class="hljs-addition">+    def add_token_type(token: Token) -&gt; Token:</span>
<span class="hljs-addition">+        token.type = char_to_token_type(token.content)</span>
<span class="hljs-addition">+</span>
<span class="hljs-addition">+        return token</span>

     tokens = [
<span class="hljs-deletion">-        location_info_to_token(info) for info in generate_location_info(code)</span>
<span class="hljs-addition">+        add_token_type(token) for token in generate_token_locations(code)</span>
     ]</pre>

<br>
<p>And in our tests:</p>
<br>
<pre class="hljs"><span class="hljs-deletion">-from wac.parse.token import Token, TokenType, generate_location_info, tokenize</span>
<span class="hljs-addition">+from wac.parse.token import (</span>
<span class="hljs-addition">+    Token,</span>
<span class="hljs-addition">+    TokenType,</span>
<span class="hljs-addition">+    generate_token_locations,</span>
<span class="hljs-addition">+    tokenize,</span>
<span class="hljs-addition">+)</span>

 ...

 def test_generate_location_info():
<span class="hljs-deletion">-    locations = list(generate_location_info(&quot;a\nbc\ndef&quot;))</span>
<span class="hljs-addition">+    locations = list(generate_token_locations(&quot;a\nbc\ndef&quot;))</span>

     assert locations == [
<span class="hljs-deletion">-        (&quot;a&quot;, 1, 1),</span>
<span class="hljs-deletion">-        (&quot;\n&quot;, 1, 2),</span>
<span class="hljs-deletion">-        (&quot;b&quot;, 2, 1),</span>
<span class="hljs-deletion">-        (&quot;c&quot;, 2, 2),</span>
<span class="hljs-deletion">-        (&quot;\n&quot;, 2, 3),</span>
<span class="hljs-deletion">-        (&quot;d&quot;, 3, 1),</span>
<span class="hljs-deletion">-        (&quot;e&quot;, 3, 2),</span>
<span class="hljs-deletion">-        (&quot;f&quot;, 3, 3),</span>
<span class="hljs-addition">+        Token(&quot;a&quot;, 1, 1),</span>
<span class="hljs-addition">+        Token(&quot;\n&quot;, 1, 2),</span>
<span class="hljs-addition">+        Token(&quot;b&quot;, 2, 1),</span>
<span class="hljs-addition">+        Token(&quot;c&quot;, 2, 2),</span>
<span class="hljs-addition">+        Token(&quot;\n&quot;, 2, 3),</span>
<span class="hljs-addition">+        Token(&quot;d&quot;, 3, 1),</span>
<span class="hljs-addition">+        Token(&quot;e&quot;, 3, 2),</span>
<span class="hljs-addition">+        Token(&quot;f&quot;, 3, 3),</span>
     ]</pre>

<br>
<p>Refactoring done!</p>
<br>
<h2>Fixing isort</h2>
<br>
<p>Remember that isort is what we use for sorting our imports. We didn't set it up
in our first blog post, so now we need to configure it (the imports in the test
file is too long, and not being formatted correctly).</p>
<br>
<p>In <code class="hljs">.isort.cfg</code>:</p>
<br>
<pre class="hljs"><span class="hljs-section">[settings]</span>
<span class="hljs-attr">multi_line_output</span>=<span class="hljs-number">3</span>
<span class="hljs-attr">include_trailing_comma</span>=<span class="hljs-literal">true</span>
<span class="hljs-attr">color_output</span>=<span class="hljs-literal">true</span></pre>

<br>
<p>Since we have color output, we will also need to update our <code class="hljs">dev-requirements.txt</code>
file:</p>
<br>
<pre class="hljs"> click==8.0.4
<span class="hljs-addition">+colorama==0.4.4</span>
 coverage==6.3.2</pre>

<br>
<blockquote>Don't forget to re-run <code class="hljs">pip install -r dev-requirements.txt</code> afterwards!</blockquote>
<br>
<p>Now when we run <code class="hljs">make isort</code>, it will tell us if isort was successful or not, and
give us an indication of what failed. Note that it will not return a non-zero exit
code upon failure, which means our CI workflow would silently fail! We can fix this
by adding the following to our <code class="hljs">Makefile</code>:</p>
<br>
<pre class="hljs"> isort:
<span class="hljs-deletion">-       isort . --diff</span>
<span class="hljs-addition">+       isort . --diff --check</span></pre>

<br>
<p>That's it!</p>
<br>
<h2>What's Next</h2>
<br>
<p>In the next blog post, we will discuss the general structure of our new programming
language, and how we will structure our AST nodes. After that, we will write an
AST parser to create said nodes.</p>
<br>
<p>[<a href="./writing-a-compiler-2.html">prev</a>]</p>
<br>
<main>

</body>
</html>
